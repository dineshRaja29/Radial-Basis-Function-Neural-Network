{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOt1wio3ajd6zoawRKXzB3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshRaja29/Radial-Basis-Function-Neural-Network/blob/main/rbfANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HQz5R3kZVYOE"
      },
      "outputs": [],
      "source": [
        "# Shri Radhey"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> INTRODUCTION"
      ],
      "metadata": {
        "id": "ym29VTkgRoTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GOAL:** Trying to build the alternative of the Neural Network when data have radial symmetry instead of linear symmetry.These type of network are called Radial basis function (RBF) network\n",
        "\n",
        "**RBF**\n",
        "- Radial basis function (RBF) network is an artificial neural network that uses radial basis functions as activation functions.\n",
        "- The output of the network is a linear combination of radial basis functions of the inputs and neuron parameters.\n",
        "- Implementing the Radial Basis Function (RBF) Network from scratch, there is no standard implementation in the PyTorch library to the best of my knowledge.\n",
        "\n",
        "\n",
        "![RBF Network](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Rbf-network.svg/800px-Rbf-network.svg.png)\n"
      ],
      "metadata": {
        "id": "s8QkJ_bOSf8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> PERFORMANCE METRIC\n",
        "- Accuracy\n",
        "- F1 Score"
      ],
      "metadata": {
        "id": "68CrTNUyWG8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> CONSTRAINTS\n",
        "- Data have partial or full radial symmetry"
      ],
      "metadata": {
        "id": "YHiwO7w7WaK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> DATASET\n",
        "- Data is borrowed from https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html\n",
        "- This is toy dataset which have large circle containing a smaller circle in 2d."
      ],
      "metadata": {
        "id": "6_Bs5kDgXcwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> MODEL BUILDING"
      ],
      "metadata": {
        "id": "99ydV5JxYEyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the necessary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_circles\n",
        "import numpy as np\n",
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "Ki_kll_X8Qdv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config variables\n",
        "INPUT_DIM = 2\n",
        "OUTPUT_DIM = 2\n",
        "SPLIT_RATIO = 0.2\n",
        "L2_PENALTY = 0.001\n",
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 8\n",
        "NUM_OF_EPOCHS = 50\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'NOTE: Hardware on which most of the computation run is {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jirzc6LyWjVf",
        "outputId": "0fe57fba-2a33-4f99-e292-b7d89bac5871"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Hardware on which most of the computation run is cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function\n",
        "def calculate_accuracy(loader, model):\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_X, batch_y in loader:\n",
        "            batch_X = batch_X.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "            outputs = model(batch_X)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "nAMO1ZySg0E5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading and converting to PyTorch format\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X, y = make_circles(n_samples=10000, noise=0.05, random_state=42)\n",
        "\n",
        "# spliting the data\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = SPLIT_RATIO, stratify = y)\n",
        "\n",
        "# standardize data without leakage\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "## reference: https://stackoverflow.com/questions/67683406/difference-between-dataset-and-tensordataset-in-pytorch\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "# Create DataLoader for testing\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False)\n"
      ],
      "metadata": {
        "id": "IwoZ3_sM853r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'green'> <b> BASELINE (FF-DNN)"
      ],
      "metadata": {
        "id": "EyzWt6Wrbb2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feed Forward Deep Neural Network (FF-DNN) is our baseline model with ReLU as activation function\n",
        "- The number of hidden layers and activation units are same as RBF\n",
        "- Using the standard implementation from PyTorch\n"
      ],
      "metadata": {
        "id": "sZLVoJmgbn-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinearNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLinearNetwork, self).__init__()\n",
        "        # Sequential container for defining the network architecture\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(INPUT_DIM, 2 * INPUT_DIM),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2 * INPUT_DIM, OUTPUT_DIM),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Apply Xavier initialization to the linear layers\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                init.xavier_normal_(layer.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the defined layers\n",
        "        return self.layers(x)\n",
        "\n",
        "model = MyLinearNetwork()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7JswT4213Ru",
        "outputId": "324dcc6f-bf25-4d71-ecb0-d3108be61652"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyLinearNetwork(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=2, out_features=4, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=4, out_features=2, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TRAINING LOOP ##\n",
        "# Define your loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "BEST_LOSS = np.inf\n",
        "\n",
        "# Training loop with DataLoader\n",
        "\n",
        "for epoch in range(NUM_OF_EPOCHS):\n",
        "\n",
        "    model.train() # setting model stage to training\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # normalizing with number of batches\n",
        "    total_loss = total_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_OF_EPOCHS}, Loss: {total_loss}\")\n",
        "\n",
        "    if  total_loss < BEST_LOSS:\n",
        "        print('Updating the checkpoint')\n",
        "        BEST_LOSS = total_loss\n",
        "        torch.save(model.state_dict(), '/content/linear_model.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j31O0Cxv13Uh",
        "outputId": "3dc0d9f2-1c11-427f-e85e-e02b3ec5c80f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.6986931726336479\n",
            "Updating the checkpoint\n",
            "Epoch 2/50, Loss: 0.6906988353729248\n",
            "Updating the checkpoint\n",
            "Epoch 3/50, Loss: 0.6897462752461433\n",
            "Updating the checkpoint\n",
            "Epoch 4/50, Loss: 0.6894357318282127\n",
            "Updating the checkpoint\n",
            "Epoch 5/50, Loss: 0.6891173392534256\n",
            "Updating the checkpoint\n",
            "Epoch 6/50, Loss: 0.6888076118826866\n",
            "Updating the checkpoint\n",
            "Epoch 7/50, Loss: 0.6886007885336876\n",
            "Updating the checkpoint\n",
            "Epoch 8/50, Loss: 0.6883324218988418\n",
            "Updating the checkpoint\n",
            "Epoch 9/50, Loss: 0.6880211118459701\n",
            "Updating the checkpoint\n",
            "Epoch 10/50, Loss: 0.6878049199581147\n",
            "Updating the checkpoint\n",
            "Epoch 11/50, Loss: 0.6874026858210563\n",
            "Updating the checkpoint\n",
            "Epoch 12/50, Loss: 0.6870764989256859\n",
            "Updating the checkpoint\n",
            "Epoch 13/50, Loss: 0.6864045936465263\n",
            "Updating the checkpoint\n",
            "Epoch 14/50, Loss: 0.6852859667539597\n",
            "Updating the checkpoint\n",
            "Epoch 15/50, Loss: 0.6830416114330292\n",
            "Updating the checkpoint\n",
            "Epoch 16/50, Loss: 0.6803556940555573\n",
            "Updating the checkpoint\n",
            "Epoch 17/50, Loss: 0.6781336164474487\n",
            "Updating the checkpoint\n",
            "Epoch 18/50, Loss: 0.6756920936703682\n",
            "Updating the checkpoint\n",
            "Epoch 19/50, Loss: 0.6734801785349845\n",
            "Updating the checkpoint\n",
            "Epoch 20/50, Loss: 0.6711968516707421\n",
            "Updating the checkpoint\n",
            "Epoch 21/50, Loss: 0.6684702427387238\n",
            "Updating the checkpoint\n",
            "Epoch 22/50, Loss: 0.6649503964781761\n",
            "Updating the checkpoint\n",
            "Epoch 23/50, Loss: 0.6600514237880707\n",
            "Updating the checkpoint\n",
            "Epoch 24/50, Loss: 0.6566937275528908\n",
            "Updating the checkpoint\n",
            "Epoch 25/50, Loss: 0.6540640259981155\n",
            "Updating the checkpoint\n",
            "Epoch 26/50, Loss: 0.6514509770870208\n",
            "Updating the checkpoint\n",
            "Epoch 27/50, Loss: 0.6488146665990353\n",
            "Updating the checkpoint\n",
            "Epoch 28/50, Loss: 0.646551376670599\n",
            "Updating the checkpoint\n",
            "Epoch 29/50, Loss: 0.6437148676514626\n",
            "Updating the checkpoint\n",
            "Epoch 30/50, Loss: 0.6405700244307518\n",
            "Updating the checkpoint\n",
            "Epoch 31/50, Loss: 0.6375565899908543\n",
            "Updating the checkpoint\n",
            "Epoch 32/50, Loss: 0.6342157375514508\n",
            "Updating the checkpoint\n",
            "Epoch 33/50, Loss: 0.6310237200558185\n",
            "Updating the checkpoint\n",
            "Epoch 34/50, Loss: 0.6280464295744896\n",
            "Updating the checkpoint\n",
            "Epoch 35/50, Loss: 0.6248945182561875\n",
            "Updating the checkpoint\n",
            "Epoch 36/50, Loss: 0.6213835968375206\n",
            "Updating the checkpoint\n",
            "Epoch 37/50, Loss: 0.6185964970886707\n",
            "Updating the checkpoint\n",
            "Epoch 38/50, Loss: 0.6158357219398022\n",
            "Updating the checkpoint\n",
            "Epoch 39/50, Loss: 0.6131539491713047\n",
            "Updating the checkpoint\n",
            "Epoch 40/50, Loss: 0.6104021447896958\n",
            "Updating the checkpoint\n",
            "Epoch 41/50, Loss: 0.6079446200728417\n",
            "Updating the checkpoint\n",
            "Epoch 42/50, Loss: 0.6050350236296653\n",
            "Updating the checkpoint\n",
            "Epoch 43/50, Loss: 0.6029737034142018\n",
            "Updating the checkpoint\n",
            "Epoch 44/50, Loss: 0.6003954550623893\n",
            "Updating the checkpoint\n",
            "Epoch 45/50, Loss: 0.5982573227286339\n",
            "Updating the checkpoint\n",
            "Epoch 46/50, Loss: 0.5959500286877155\n",
            "Updating the checkpoint\n",
            "Epoch 47/50, Loss: 0.5939844388067722\n",
            "Updating the checkpoint\n",
            "Epoch 48/50, Loss: 0.5921002379655838\n",
            "Updating the checkpoint\n",
            "Epoch 49/50, Loss: 0.5903290675580501\n",
            "Updating the checkpoint\n",
            "Epoch 50/50, Loss: 0.5886124640703201\n",
            "Updating the checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PERFORMANCE EVALUATION\n",
        "# loading the best model\n",
        "model = MyLinearNetwork()\n",
        "model.load_state_dict(torch.load('/content/linear_model.pt'))\n",
        "model.to(device)\n",
        "print(f\"\\n- Train Accuracy: {calculate_accuracy(train_loader, model) * 100:.2f}%\")\n",
        "print(f\"\\n- Test Accuracy: {calculate_accuracy(test_loader, model) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR6VJCK-13YF",
        "outputId": "af6aa03e-4769-410d-ec17-efd0978c0416"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Train Accuracy: 67.01%\n",
            "\n",
            "- Test Accuracy: 67.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = 'green'> <b> CANDIDATE (RBF NETWORK)"
      ],
      "metadata": {
        "id": "PmXPEaUuclW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RBF Network (https://en.wikipedia.org/wiki/Radial_basis_function_network#/media/File:Rbf-network.svg)"
      ],
      "metadata": {
        "id": "6U4A2DbsdDJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRBFLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, beta=0.1):\n",
        "        super(MyRBFLayer, self).__init__()\n",
        "        # Initialize weights with Xavier initialization\n",
        "        # output_dim and input_dim\n",
        "        self.centers = nn.Parameter(torch.randn(2 * in_features, in_features), requires_grad=True)\n",
        "        init.xavier_normal_(self.centers.data)  # Xavier initialization for centers\n",
        "        self.linear_layer = nn.Linear(2 * in_features, out_features)\n",
        "        init.xavier_normal_(self.linear_layer.weight.data)  # Xavier initialization for linear layer weights\n",
        "        init.constant_(self.linear_layer.bias.data, 0)  # Set bias to zero\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Implement the forward pass\n",
        "        distances = torch.sum((x.unsqueeze(1) - self.centers) ** 2, dim=2, keepdim=True)\n",
        "        radial_symmetry = torch.exp(-self.beta * distances)\n",
        "        linear_symmetry = self.linear_layer(radial_symmetry.squeeze())\n",
        "        return linear_symmetry\n",
        "\n",
        "class MyRBFNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyRBFNetwork, self).__init__()\n",
        "        self.hidden_layer1 = MyRBFLayer(INPUT_DIM, OUTPUT_DIM)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden_output1 = self.hidden_layer1(x)\n",
        "        return hidden_output1\n",
        "\n",
        "model = MyRBFNetwork()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Udi1jajBNQ",
        "outputId": "228cb097-a422-46a3-8047-ec7cc29c5707"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyRBFNetwork(\n",
              "  (hidden_layer1): MyRBFLayer(\n",
              "    (linear_layer): Linear(in_features=4, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class MyLinearLayer(nn.Module):\n",
        "#     def __init__(self, in_features, out_features):\n",
        "#         super(MyLinearLayer, self).__init__()\n",
        "#         # Initialize weights\n",
        "#         self.weights = nn.Parameter(torch.randn(out_features, in_features))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         print(x.shape, self.weights.shape)\n",
        "#         return torch.matmul(x, self.weights.t())\n"
      ],
      "metadata": {
        "id": "vlaYZvmfWLFm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TRAINING LOOP ##\n",
        "# Define your loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "BEST_LOSS = np.inf\n",
        "\n",
        "# Training loop with DataLoader\n",
        "\n",
        "for epoch in range(NUM_OF_EPOCHS):\n",
        "\n",
        "    model.train() # setting model stage to training\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # normalizing with number of batches\n",
        "    total_loss = total_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_OF_EPOCHS}, Loss: {total_loss}\")\n",
        "\n",
        "    if  total_loss < BEST_LOSS:\n",
        "        print('Updating the checkpoint')\n",
        "        BEST_LOSS = total_loss\n",
        "        torch.save(model.state_dict(), '/content/rbf_model.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZptnCujFjl9",
        "outputId": "52ed642f-26e7-4583-cc9f-eea982afa48b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.6940061441659927\n",
            "Updating the checkpoint\n",
            "Epoch 2/50, Loss: 0.6866713054180146\n",
            "Updating the checkpoint\n",
            "Epoch 3/50, Loss: 0.6813645353913307\n",
            "Updating the checkpoint\n",
            "Epoch 4/50, Loss: 0.6756566749215126\n",
            "Updating the checkpoint\n",
            "Epoch 5/50, Loss: 0.6700254489779472\n",
            "Updating the checkpoint\n",
            "Epoch 6/50, Loss: 0.6641248695254326\n",
            "Updating the checkpoint\n",
            "Epoch 7/50, Loss: 0.6583865784406662\n",
            "Updating the checkpoint\n",
            "Epoch 8/50, Loss: 0.6531862029433251\n",
            "Updating the checkpoint\n",
            "Epoch 9/50, Loss: 0.6475702694058418\n",
            "Updating the checkpoint\n",
            "Epoch 10/50, Loss: 0.6418798626661301\n",
            "Updating the checkpoint\n",
            "Epoch 11/50, Loss: 0.6366446309089661\n",
            "Updating the checkpoint\n",
            "Epoch 12/50, Loss: 0.6310571937561035\n",
            "Updating the checkpoint\n",
            "Epoch 13/50, Loss: 0.6257547313570976\n",
            "Updating the checkpoint\n",
            "Epoch 14/50, Loss: 0.6205036726593971\n",
            "Updating the checkpoint\n",
            "Epoch 15/50, Loss: 0.6154106248021126\n",
            "Updating the checkpoint\n",
            "Epoch 16/50, Loss: 0.6101664971113205\n",
            "Updating the checkpoint\n",
            "Epoch 17/50, Loss: 0.6049981832504272\n",
            "Updating the checkpoint\n",
            "Epoch 18/50, Loss: 0.5998681689500809\n",
            "Updating the checkpoint\n",
            "Epoch 19/50, Loss: 0.5948911618590355\n",
            "Updating the checkpoint\n",
            "Epoch 20/50, Loss: 0.5895132820010185\n",
            "Updating the checkpoint\n",
            "Epoch 21/50, Loss: 0.5852560943961144\n",
            "Updating the checkpoint\n",
            "Epoch 22/50, Loss: 0.5801072481870652\n",
            "Updating the checkpoint\n",
            "Epoch 23/50, Loss: 0.5753327225744724\n",
            "Updating the checkpoint\n",
            "Epoch 24/50, Loss: 0.5710507987141609\n",
            "Updating the checkpoint\n",
            "Epoch 25/50, Loss: 0.5662152700424194\n",
            "Updating the checkpoint\n",
            "Epoch 26/50, Loss: 0.56155026653409\n",
            "Updating the checkpoint\n",
            "Epoch 27/50, Loss: 0.5571974851191044\n",
            "Updating the checkpoint\n",
            "Epoch 28/50, Loss: 0.5528347094058991\n",
            "Updating the checkpoint\n",
            "Epoch 29/50, Loss: 0.5484630179107189\n",
            "Updating the checkpoint\n",
            "Epoch 30/50, Loss: 0.5439185295701027\n",
            "Updating the checkpoint\n",
            "Epoch 31/50, Loss: 0.5397345893979073\n",
            "Updating the checkpoint\n",
            "Epoch 32/50, Loss: 0.5351924920678138\n",
            "Updating the checkpoint\n",
            "Epoch 33/50, Loss: 0.5312315669357777\n",
            "Updating the checkpoint\n",
            "Epoch 34/50, Loss: 0.5269994866847992\n",
            "Updating the checkpoint\n",
            "Epoch 35/50, Loss: 0.5233668976724147\n",
            "Updating the checkpoint\n",
            "Epoch 36/50, Loss: 0.5191334608793259\n",
            "Updating the checkpoint\n",
            "Epoch 37/50, Loss: 0.5153128536939621\n",
            "Updating the checkpoint\n",
            "Epoch 38/50, Loss: 0.5114857232570649\n",
            "Updating the checkpoint\n",
            "Epoch 39/50, Loss: 0.5075437003970146\n",
            "Updating the checkpoint\n",
            "Epoch 40/50, Loss: 0.5040830761790276\n",
            "Updating the checkpoint\n",
            "Epoch 41/50, Loss: 0.5002634724974633\n",
            "Updating the checkpoint\n",
            "Epoch 42/50, Loss: 0.4966282264590263\n",
            "Updating the checkpoint\n",
            "Epoch 43/50, Loss: 0.49308327263593676\n",
            "Updating the checkpoint\n",
            "Epoch 44/50, Loss: 0.4896679913699627\n",
            "Updating the checkpoint\n",
            "Epoch 45/50, Loss: 0.4862318206429482\n",
            "Updating the checkpoint\n",
            "Epoch 46/50, Loss: 0.4827943514585495\n",
            "Updating the checkpoint\n",
            "Epoch 47/50, Loss: 0.4794257410764694\n",
            "Updating the checkpoint\n",
            "Epoch 48/50, Loss: 0.47607161596417424\n",
            "Updating the checkpoint\n",
            "Epoch 49/50, Loss: 0.47288344356417655\n",
            "Updating the checkpoint\n",
            "Epoch 50/50, Loss: 0.4698050751388073\n",
            "Updating the checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PERFORMANCE EVALUATION\n",
        "# loading the best model\n",
        "model = MyRBFNetwork()\n",
        "model.load_state_dict(torch.load('/content/rbf_model.pt'))\n",
        "model.to(device)\n",
        "print(f\"\\n- Train Accuracy: {calculate_accuracy(train_loader, model) * 100:.2f}%\")\n",
        "print(f\"\\n- Test Accuracy: {calculate_accuracy(test_loader, model) * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtDK6f6mhtIi",
        "outputId": "0403f22b-6955-4e08-eec9-23f197a78772"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "- Train Accuracy: 97.14%\n",
            "\n",
            "- Test Accuracy: 97.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> RESULTS"
      ],
      "metadata": {
        "id": "NdY2lDc6dkUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = PrettyTable()\n",
        "x.field_names = [\"Sr. No.\", \"EXPERIMENT\", \"#f Intermediate Layers\", \" Training Accuray\", \"Test Accuracy\"]\n",
        "x.add_row([1, 'Baseline (FF-DNN)', 2, 67.01, 67.10])\n",
        "x.add_row([2, 'Candidate (RBF)', 2, 97.14, 97.55])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfz3F0nMba-p",
        "outputId": "5e66a977-ea4a-4e73-cd12-e5b921e3a13b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+------------------------+-------------------+---------------+\n",
            "| Sr. No. |     EXPERIMENT    | #f Intermediate Layers |  Training Accuray | Test Accuracy |\n",
            "+---------+-------------------+------------------------+-------------------+---------------+\n",
            "|    1    | Baseline (FF-DNN) |           2            |       67.01       |      67.1     |\n",
            "|    2    |  Candidate (RBF)  |           2            |       97.14       |     97.55     |\n",
            "+---------+-------------------+------------------------+-------------------+---------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = 'green'> <b> CONCLUSION"
      ],
      "metadata": {
        "id": "TSFXaOJJiHvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- When data have radial symmetry then RBF network performs better than FF-DNN\n",
        "- RBF Network Generalize better on the test data compare to FF-DNN when data have radial symmetry"
      ],
      "metadata": {
        "id": "EIt3ECDgiMJN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWO__wlJ5CKS"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}